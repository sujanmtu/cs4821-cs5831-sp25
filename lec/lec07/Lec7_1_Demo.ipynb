{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e5RcJaUkawr"
      },
      "source": [
        "# Case Study: AdaBoost, Gradient Boosting, and XGBoost Classification using the Breast Cancer Dataset\n",
        "\n",
        "In this case study, we will classify the Breast Cancer dataset using three boosting algorithms:\n",
        "1. **AdaBoost**\n",
        "2. **Gradient Boosting**\n",
        "3. **XGBoost**\n",
        "\n",
        "We will go through the following steps:\n",
        "1. **Importing Libraries**: Required libraries for data preprocessing, model training, and evaluation.\n",
        "2. **Data Loading and Preprocessing**: Loading the dataset, splitting the data into training and test sets, and standardizing the features.\n",
        "3. **Model Training**: Training the models using AdaBoost, Gradient Boosting, and XGBoost.\n",
        "4. **Evaluation**: Making predictions and evaluating the models using confusion matrices and classification reports."
      ],
      "id": "7e5RcJaUkawr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43PaJK8ikawt"
      },
      "outputs": [],
      "source": [
        "# Step 1: Import Libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "id": "43PaJK8ikawt"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLnXANLDkawu"
      },
      "source": [
        "### Step 2: Load and Preprocess the Breast Cancer Dataset\n",
        "\n",
        "In this step, we will:\n",
        "- Load the Breast Cancer dataset.\n",
        "- Extract the features (X) and labels (y).\n",
        "- Select only the first two features for visualization.\n",
        "- Split the dataset into training and test sets.\n",
        "- Standardize the features using `StandardScaler` to ensure that they have zero mean and unit variance."
      ],
      "id": "oLnXANLDkawu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XlyjSThzkawv"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "cancer = datasets.load_breast_cancer()\n",
        "X, y = cancer.data, cancer.target  # Features & labels\n",
        "\n",
        "# Select first two features for visualization\n",
        "X = X[:, :10]\n",
        "\n",
        "# Split dataset into train & test sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Display dataset shapes\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "id": "XlyjSThzkawv"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMPs4rjskawv"
      },
      "source": [
        "### Step 3: Train the Boosting Models\n",
        "\n",
        "Now we will train the following models:\n",
        "1. **AdaBoost**: Using AdaBoostClassifier.\n",
        "2. **Gradient Boosting**: Using GradientBoostingClassifier.\n",
        "3. **XGBoost**: Using XGBoost from the `xgboost` library.\n",
        "\n",
        "We will train each model on the training data and evaluate it on the test data."
      ],
      "id": "AMPs4rjskawv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8zVqtoukaww"
      },
      "outputs": [],
      "source": [
        "# AdaBoost Model\n",
        "adaboost_model = AdaBoostClassifier(n_estimators=50, random_state=42)\n",
        "adaboost_model.fit(X_train, y_train)\n",
        "\n",
        "# Gradient Boosting Model\n",
        "gradientboosting_model = GradientBoostingClassifier(n_estimators=50, random_state=42)\n",
        "gradientboosting_model.fit(X_train, y_train)\n",
        "\n",
        "# XGBoost Model\n",
        "xgb_model = xgb.XGBClassifier(n_estimators=50, random_state=42)\n",
        "xgb_model.fit(X_train, y_train)"
      ],
      "id": "Z8zVqtoukaww"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkBj1_-ekaww"
      },
      "source": [
        "### Step 4: Evaluate the Models\n",
        "\n",
        "We will evaluate the performance of each model using the confusion matrix and classification report.\n",
        "\n",
        "1. **Confusion Matrix**: Visualize the model's classification results.\n",
        "2. **Classification Report**: Show detailed metrics such as precision, recall, and F1-score."
      ],
      "id": "ZkBj1_-ekaww"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3E9bd_iukaww"
      },
      "outputs": [],
      "source": [
        "# Function to plot confusion matrix\n",
        "def plot_confusion_matrix(cm, title=\"Confusion Matrix\"):\n",
        "    plt.figure(figsize=(5, 4))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Benign', 'Malignant'], yticklabels=['Benign', 'Malignant'])\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "# AdaBoost Evaluation\n",
        "y_pred_adaboost = adaboost_model.predict(X_test)\n",
        "cm_adaboost = confusion_matrix(y_test, y_pred_adaboost)\n",
        "print(\"AdaBoost Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_adaboost))\n",
        "plot_confusion_matrix(cm_adaboost, title=\"AdaBoost Confusion Matrix\")\n",
        "\n",
        "# Gradient Boosting Evaluation\n",
        "y_pred_gradientboosting = gradientboosting_model.predict(X_test)\n",
        "cm_gradientboosting = confusion_matrix(y_test, y_pred_gradientboosting)\n",
        "print(\"Gradient Boosting Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_gradientboosting))\n",
        "plot_confusion_matrix(cm_gradientboosting, title=\"Gradient Boosting Confusion Matrix\")\n",
        "\n",
        "# XGBoost Evaluation\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "cm_xgb = confusion_matrix(y_test, y_pred_xgb)\n",
        "print(\"XGBoost Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_xgb))\n",
        "plot_confusion_matrix(cm_xgb, title=\"XGBoost Confusion Matrix\")"
      ],
      "id": "3E9bd_iukaww"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noLNMg3Bkawx"
      },
      "source": [
        "### Summary\n",
        "\n",
        "In this notebook, we demonstrated how to:\n",
        "1. Load and preprocess the Breast Cancer dataset.\n",
        "2. Train three boosting models: AdaBoost, Gradient Boosting, and XGBoost.\n",
        "3. Evaluate the models' performance using confusion matrices and classification reports.\n",
        "\n",
        "This example showcases the power of different boosting algorithms in binary classification tasks and how they can be evaluated in terms of accuracy, precision, recall, and F1-score."
      ],
      "id": "noLNMg3Bkawx"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}